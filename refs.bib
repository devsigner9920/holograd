@article{baydin2022gradients,
  title        = {Gradients without Backpropagation},
  author       = {Baydin, At{\i}l{\i}m G{\"u}ne{\c{s}} and Pearlmutter, Barak A. and Syme, Don and Wood, Frank and Torr, Philip},
  journal      = {arXiv preprint arXiv:2202.08587},
  year         = {2022},
  url          = {https://arxiv.org/abs/2202.08587}
}

@article{shukla2023randomized,
  title        = {Randomized Forward Mode of Automatic Differentiation For Optimization Algorithms},
  author       = {Shukla, Khemraj and Shin, Yeonjong},
  journal      = {arXiv preprint arXiv:2310.14168},
  year         = {2023},
  url          = {https://arxiv.org/abs/2310.14168}
}

@inproceedings{bernstein2018signsgd,
  title        = {signSGD: Compressed Optimisation for Non-Convex Problems},
  author       = {Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Anima},
  booktitle    = {Proceedings of the 35th International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {80},
  year         = {2018},
  url          = {https://arxiv.org/abs/1802.04434}
}

@inproceedings{jaderberg2017dni,
  title        = {Decoupled Neural Interfaces using Synthetic Gradients},
  author       = {Jaderberg, Max and Czarnecki, Wojciech Marian and Osindero, Simon and Vinyals, Oriol and Graves, Alex and Silver, David and Kavukcuoglu, Koray},
  booktitle    = {Proceedings of the 34th International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {70},
  year         = {2017},
  url          = {https://arxiv.org/abs/1608.05343}
}

@article{scalable2025bgfree,
  title        = {Towards Scalable Backpropagation-Free Gradient Estimation},
  author       = {Unknown, Placeholder},
  journal      = {arXiv preprint arXiv:2511.03110},
  year         = {2025},
  note         = {Optional citation; replace author list after confirming metadata},
  url          = {https://arxiv.org/abs/2511.03110}
}

% === Missing citations identified in paper analysis ===

@article{bacho2022lowvariance,
  title        = {Low-Variance Forward Gradients using Direct Feedback Alignment and Momentum},
  author       = {Bacho, Florian and Chu, Dominique},
  journal      = {arXiv preprint arXiv:2212.07282},
  year         = {2022},
  url          = {https://arxiv.org/abs/2212.07282},
  note         = {Uses momentum to reduce forward gradient variance - similar to HoloGrad momentum-centric variant}
}

@article{jain2016streaming,
  title        = {Streaming PCA: Matching Matrix Bernstein and Near-Optimal Finite Sample Guarantees for Oja's Algorithm},
  author       = {Jain, Prateek and Jin, Chi and Kakade, Sham M. and Netrapalli, Praneeth and Sidford, Aaron},
  journal      = {arXiv preprint arXiv:1602.06929},
  year         = {2016},
  url          = {https://arxiv.org/abs/1602.06929}
}

@article{huang2021streaming,
  title        = {Streaming k-PCA: Efficient guarantees for Oja's algorithm, beyond rank-one updates},
  author       = {Huang, Yichong and Huang, Longbo and Shanbhag, Uday V.},
  journal      = {arXiv preprint arXiv:2102.03646},
  year         = {2021},
  url          = {https://arxiv.org/abs/2102.03646}
}

@article{lin2017deep,
  title        = {Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training},
  author       = {Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J.},
  journal      = {arXiv preprint arXiv:1712.01887},
  year         = {2017},
  url          = {https://arxiv.org/abs/1712.01887},
  note         = {Achieves 270-600x compression via momentum correction and local gradient accumulation}
}

@article{yang2019byzantine,
  title        = {Adversary-Resilient Distributed and Decentralized Statistical Inference and Machine Learning: An Overview of Recent Advances under the Byzantine Threat Model},
  author       = {Yang, Rong and Sun, Qi and He, Lili and Xia, Youshen},
  journal      = {IEEE Signal Processing Magazine},
  volume       = {37},
  number       = {3},
  pages        = {146--159},
  year         = {2020},
  publisher    = {IEEE},
  note         = {Comprehensive survey of Byzantine-tolerant ML},
  url          = {https://arxiv.org/abs/1908.08649}
}

@article{ren2022scaling,
  title        = {Scaling Forward Gradient With Local Losses},
  author       = {Ren, Mengye and Kornblith, Simon and Liao, Renjie and Hinton, Geoffrey},
  journal      = {arXiv preprint arXiv:2210.03310},
  year         = {2022},
  url          = {https://arxiv.org/abs/2210.03310},
  note         = {Identifies high variance problem of forward gradients in high dimensions}
}
